---
title: "Parler_ML_Models"
author: "Dominik BÃ¤r"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ##################################################################################################################
#    File analyses parleys (posts/comments)
# ##################################################################################################################

# Environment

```{r library, include=FALSE}

library(tidyverse)
library(caret)
library(doParallel)
library(furrr)
library(xgboost)
library(ranger)
library(glmnet)
library(fastDummies)
library(pROC)
library(verification)

# Python setup
library(reticulate)
library(tensorflow)
library(keras)


# reticulate::py_install('tensorflow', pip = TRUE)
#tf = reticulate::import("tensorflow")
#builtins <- import_builtins() #built in python methods

set.seed(1234)

```

# Directories

```{r paths, include = FALSE}

path_output <- "../../Data/output/"

```

Load feature sets

```{r}

# User features
load(str_c(path_output, "features_user.Rdata")) 
# Linguistic featues
load(str_c(path_output, "features_linguistic.Rdata"))
features_empath <- read_csv(str_c(path_output, "features_empath.csv"))
features_liwc <- read_csv(str_c(path_output, "features_liwc.csv"))
features_perspective <- read_csv(str_c(path_output, "features_perspective.csv"))
features_stance <- read_csv(str_c(path_output, "features_stance.csv"))

# Network features
features_network <- read_csv(str_c(path_output, "features_network.csv"))

# Content features
features_content <- read_csv(str_c(path_output, "features_bert.csv"))

```

# Features

```{r}

# Rename LIWC and Empaht features (some names are the same)
features_empath <- rename_with(features_empath, .cols = names(features_empath[-1]), ~ str_c(names(features_empath[-1]), "_empath"))
features_liwc <- rename_with(features_liwc, .cols = names(features_liwc[-1]), ~ str_c(names(features_liwc[-1]), "_liwc"))

# Vector with feature names
names_features_user <- c("account_age", "user_followers", "user_following" , "user_posts", "user_comments", "freq_upvotes_posts", "freq_impressions", "freq_upvotes_comments", "freq_downvotes_comments")
names_features_stylistic <- c("freq_handle_user", "freq_hash_user", "freq_pos_user", "freq_long_words_user", "freq_urls", "user_sentiment", names(features_empath[-1]), names(features_liwc[-1]), names(features_perspective[-1]), "stance_qanon")
names_features_network <- c("degree_in", "degree_out", "eigen_left", "betweenness")
names_features_text <- str_c("text", c(0:383))
names_features_all <- c(names_features_user, names_features_stylistic, names_features_network, names_features_text)
names_features <- c("features_user", "features_stylistic", "features_network", "features_text", "features_all")

```

# Combine features sets

```{r}

# Combine feature sets
features_all <- features_user %>%
  left_join(features_content, by = "creator") %>%
  left_join(features_linguistic, by = "creator") %>%
  left_join(features_empath, by = "creator") %>%
  left_join(features_liwc, by = "creator") %>%
  left_join(features_perspective, by = "creator") %>%
  left_join(features_stance, by = "creator") %>%
  left_join(features_network, by = "creator") %>%
  dplyr::select(-qIndicator.y) %>%
  rename("qIndicator" = "qIndicator.x")

# Impute missing values
features_all <- features_all %>%
  mutate(across(.cols = everything(), ~ ifelse(is.na(.x), 0, .x)))

```

# Train and test split

```{r}

# Proportion of train/test data
p_train <- 0.8

# Create index for train and test split
index_training <- createDataPartition(features_all$qIndicator, p = p_train, list = FALSE, times = 1)

# Extract users for testing and training split
users_train <- features_all %>%
  dplyr::select(creator) %>%
  dplyr::slice(index_training)

users_test <- features_all %>%
  dplyr::select(creator) %>%
  dplyr::slice(-index_training)

# Append features for users in respective split
# Unbalanced: Training
train_ub <- features_all %>%
  anti_join(users_test, by = "creator") %>%
  dplyr::select(-creator) %>%
  mutate(qIndicator = factor(qIndicator, labels = c("non.QAnon", "QAnon"))) %>%
  dplyr::select(qIndicator, all_of(names_features_all))

# Testing
test <- features_all %>%
  anti_join(users_train, by = "creator") %>%
  dplyr::select(-creator) %>%
  mutate(qIndicator = factor(qIndicator, labels = c("non.QAnon", "QAnon"))) %>%
  dplyr::select(qIndicator, all_of(names_features_all))

# Number of QAnon in samples
# Train
n_qanon_train <- sum(train_ub$qIndicator == "QAnon")
# Test
n_qanon_test <- sum(test$qIndicator == "QAnon")

# Production data
train_prod <- train_ub %>% group_by(qIndicator) %>% slice_sample(n = n_qanon_train) %>% ungroup()
write_csv(train_prod, str_c(path_output, "ml_models/train_prod.csv"))
test_prod <- test %>% group_by(qIndicator) %>% slice_sample(n = n_qanon_test) %>% ungroup()
write_csv(test_prod, str_c(path_output, "ml_models/test_prod.csv"))

# Load data
train_prod <- read_csv(str_c(path_output, "ml_models/train_prod.csv"))
test_prod <- read_csv(str_c(path_output, "ml_models/test_prod.csv"))

```

Parallel processing

```{r}

cores <- detectCores()
cl <- makePSOCKcluster(cores-1)

```

## Train Control
```{r trcntrl, include=FALSE}

trcontrol = trainControl(
    method = "cv",
    number = 10,
    #repeats = 5,
    verboseIter = TRUE,
    returnData = FALSE,
    returnResamp = "none",
    classProbs = TRUE, # set to TRUE for AUC to be computed
    summaryFunction = twoClassSummary,
    allowParallel = TRUE
  )

```

## Gradient Boosting

```{r gradient boosting, include=FALSE}

fit_xgb <- function(data_train, data_test, feature_set){
  
  # data_train: dataset to train the model
  # feature set: character vector of features to use for modeling
  # tuningGrid: Grid of tuning parameters (Default: No tuning grid)
  
  formula_features <- formula(str_c("qIndicator ~ ", str_c(feature_set, collapse = "+")))
  
  # Model Setup: XGBoost
  
  model_xgb <- caret::train(formula_features,
                            data = data_train,
                            method = "xgbTree",
                            metric = "ROC",
                            trControl = trcontrol,
                            preProcess=c("center", "scale"),
                            tuneLength = 5
                            )
  
  # Prediction: XGBoost
  pred_xgb <- predict(model_xgb, data_test)

  # ROC: XGBoost
  roc_xgb <- roc(data_test$qIndicator, as.numeric(pred_xgb)) 
  roc_plot_xgb <- ggroc(roc_xgb)

  # AUC: XGBoost
  auc_xgb <- auc(roc_xgb)
  
  # Confusion Matrix: XGBoost
  cm_xgb <- confusionMatrix(pred_xgb, as_factor(data_test$qIndicator), positive = "QAnon", mode = "everything")
  
  output <- list(model_xgb, pred_xgb, roc_xgb, auc_xgb, cm_xgb)
  names(output) <- c("model", "prediciton", "roc", "auc", "ConfusionMatrix")
  return(output)
}

registerDoParallel(cl)

results_user_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_user)
results_stylistic_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_stylistic)
results_network_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_network)
results_text_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_text)
results_all_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_all)
save(results_all_xgb, file = str_c(path_output, "ml_models/results_all_xgb.Rdata"))

stopCluster(cl)

results_xgb <- list(results_user_xgb, results_stylistic_xgb, results_network_xgb, results_text_xgb, results_all_xgb)
names(results_xgb) <- names_features

save(results_xgb, file = str_c(path_dss, "output/", "results_xgb.Rdata"))

```

## Lasso Regression

```{r lasso regression, include=FALSE}

fit_lasso <- function(data_train, data_test, feature_set){
  
  # data_train: dataset to train the model
  # feature set: character vector of features to use for modeling
  # tuningGrid: Grid of tuning parameters (Default: No tuning grid)
  
  formula_features <- formula(str_c("qIndicator ~ ", str_c(feature_set, collapse = "+")))
  
  # Set up GridSearch for Lasso:
  lasso_grid <- expand.grid(
    alpha = 1,
    lambda = 10^seq(-3, 3, length = 100)
  )
  
  # Train Lasso model:
  model_lasso <- caret::train(formula_features,
                              data = data_train,
                              method = "glmnet",
                              metric = "ROC",
                              trControl = trcontrol,
                              preProcess=c("center", "scale"),
                              tuneGrid = lasso_grid
                              )

  # Prediction: Lasso
  pred_lasso <- predict(model_lasso, data_test)

  # ROC: Lasso
  roc_lasso <- roc(data_test$qIndicator, as.numeric(pred_lasso)) 
  roc_plot_lasso <- ggroc(roc_lasso)

  # AUC: Lasso
  auc_lasso <- auc(roc_lasso)
  
  # Confusion Matrix: Lasso
  cm_lasso <- confusionMatrix(pred_lasso, as_factor(data_test$qIndicator), positive = "QAnon", mode = "everything")
  
  output <- list(model_lasso, pred_lasso, roc_lasso, auc_lasso, cm_lasso)
  names(output) <- c("model", "prediciton", "roc", "auc", "ConfusionMatrix")
  return(output)
}

results_user_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_user)
results_stylistic_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_stylistic)
results_network_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_network)
results_text_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_text)
results_all_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_all)

results_lasso <- list(results_user_lasso, results_stylistic_lasso, results_network_lasso ,results_text_lasso, results_all_lasso)
names(results_lasso) <- names_features

save(results_lasso, file = str_c(path_output, "models/", "results_lasso.Rdata"))

```

## Random Forest

```{r random forest, include=FALSE}

fit_rf <- function(data_train, data_test, feature_set){
  
  # data_train: dataset to train the model
  # feature set: character vector of features to use for modeling
  # tuningGrid: Grid of tuning parameters (Default: No tuning grid)
  
  formula_features <- formula(str_c("qIndicator ~ ", str_c(feature_set, collapse = "+")))
  
  # Model Setup: Random Forest 
  model_rf <- caret::train(formula_features,
                           data = data_train,
                           method = "ranger",
                           metric = "ROC",
                           trControl = trcontrol,
                           preProcess=c("center", "scale"),   
                           tuneLength = 10
                           )
  
  # Prediction: Random Forest
  pred_rf <- predict(model_rf, data_test)

  # ROC: Random Forest
  roc_rf <- roc(data_test$qIndicator, as.numeric(pred_rf)) 
  roc_plot_rf <- ggroc(roc_rf)

  # AUC: Random Forest
  auc_rf <- auc(roc_rf)
  
  # Confusion Matrix: Random Forest
  cm_rf <- confusionMatrix(pred_rf, as_factor(data_test$qIndicator), positive = "QAnon", mode = "everything")
  
  output <- list(model_rf, pred_rf, roc_rf, auc_rf, cm_rf)
  names(output) <- c("model", "prediciton", "roc", "auc", "ConfusionMatrix")
  return(output)
}

registerDoParallel(cl)

results_user_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_user)
results_stylistic_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_stylistic)
save(results_stylistic_rf, file = str_c(path_output, "ml_models/results_stylistic_rf.Rdata"))
results_network_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_network)
results_text_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_text)
results_all_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_all)
save(results_all_rf, file = str_c(path_output, "ml_models/results_all_rf.Rdata"))

stopCluster(cl)

results_rf <- list(results_user_rf, results_stylistic_rf, results_network_rf, results_text_rf, results_all_rf)
names(results_rf) <- names_features

save(results_rf, file = str_c(path_dss, "output/", "results_rf.Rdata"))

```

## Neural Network

```{r neural network, include=FALSE}

fit_nn <- function(data_train, data_test, feature_set){
  
  # Remove previous keras models
  keras::k_clear_session()
  
  # data_train: dataset to train the model
  # feature set: character vector of features to use for modeling
  # tuningGrid: Grid of tuning parameters (Default: No tuning grid)
  
  formula_features <- formula(str_c("qIndicator ~ ", str_c(feature_set, collapse = "+")))
  
  # Preprocess input for keras
  df.training <- data_train %>%
    dummy_cols(remove_first_dummy = TRUE) %>%
    dplyr::select(-qIndicator) %>%
    mutate(qIndicator = as_factor(qIndicator_QAnon)) %>%
    group_by(qIndicator) %>%
    mutate(id = row_number())
  
  df.train <- df.training %>%
    slice_sample(prop = 0.8) %>%
    ungroup()
  
  df.validation <- df.training %>%
    anti_join(df.train, by = "id") %>%
    ungroup() %>%
    dplyr::select(-id)
    
  df.train <- df.train %>% dplyr::select(-id) 
  
  df.test <- data_test %>%
    dummy_cols(remove_first_dummy = TRUE) %>%
    dplyr::select(-qIndicator) %>%
    mutate(qIndicator = as_factor(qIndicator_QAnon))
  
  pp <- preProcess(subset(df.train, select = -qIndicator), method = c("center", "scale"))
  df.train <- predict(pp, df.train)
  df.validation <- predict(pp, df.validation)
  df.test <- predict(pp, df.test)
  
  # Training datasets
  x_train <- df.train %>% 
    dplyr::select(-qIndicator) %>%
    dplyr::select(all_of(feature_set)) %>%
    as.matrix()
  y_train <- to_categorical(df.train$qIndicator)
  
  # Validation datasets
  x_val <- df.validation %>%
    dplyr::select(-qIndicator) %>%
    dplyr::select(all_of(feature_set)) %>%
    as.matrix()
  y_val <- to_categorical(df.validation$qIndicator)
  
  # Test datasets
  x_test <- df.test %>% 
    dplyr::select(-qIndicator) %>%
    dplyr::select(all_of(feature_set)) %>%
    as.matrix()
  y_test <- to_categorical(df.test$qIndicator)
  
  # simple early stopping
  es <- callback_early_stopping(monitor="val_loss", mode="min", verbose=2, patience=50)
  mc <- callback_model_checkpoint("best_model.h5", monitor="val_loss", mode="min", verbose=2, save_best_only=TRUE)
  
  # Network design (NN with 3 hidden layers and ReLu activation function )
  model <- keras_model_sequential()
  model %>%
  # Input layer
    layer_dense(units = 300, activation = "relu", input_shape =  ncol(x_train)) %>%
  # Hidden layer
    layer_dense(units = 100, activation = "relu") %>%
    layer_dense(units = 30, activation = "relu") %>%
    layer_dense(units = 10, activation = "relu") %>%
  # Output layer
    layer_dense(units = 2, activation = "sigmoid")
  
  # Network configuration
  history <- model %>% compile(
   loss = "binary_crossentropy",
   optimizer = "adam",
   metrics = keras$metrics$AUC()
   )
  
  # Fit Neural Network
  model_nn <- model %>% fit(x = x_train, y = y_train, 
                shuffle = T,
                batch_size = 32,
                validation_data = list(x_val, y_val),
                epochs = 1000,
                view_metrics = FALSE,
                verobse = 2,
                callbacks = list(es, mc)
                )
  
  # Prediction: Neural Network
  predictions <- model %>% predict(x_test) %>% `>`(0.5) %>% k_cast("int32")
  pred_nn <- as.data.frame(as.matrix(predictions))$V2
  
  probs_nn <- model %>% predict(x_test)
  
  # ROC: Neural Network
  roc_nn <- roc(df.test$qIndicator, pred_nn)
  roc_plot_nn <- ggroc(roc_nn)
  
  # AUC: Neural Network
  auc_nn <- auc(roc_nn)
  
  # Confusion Matrix: NN
  cm_nn <- confusionMatrix(as.factor(pred_nn), as.factor(df.test$qIndicator), positive = "1", mode = "everything")
  
  output <- list(model_nn, pred_nn, probs_nn, roc_nn, auc_nn, cm_nn)
  names(output) <- c("model", "prediciton", "probs", "roc", "auc", "ConfusionMatrix")
  return(output)
}

results_user_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_user)
results_stylistic_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_stylistic)
results_network_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_network)
results_text_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_text)
results_all_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_all)

results_nn <- list(results_user_nn, results_stylistic_nn, results_network_nn, results_text_nn, results_all_nn)
names(results_nn) <- names_features

save(results_nn, file = str_c(path_dss, "output/", "results_nn.Rdata"))

```

# Collect table of AUCs

```{r table AUCs}

metrics_xgb <- results_xgb %>%
  map_dfr(~ bind_cols(as.vector(.x[["auc"]]),
                      as.vector(.x[["ConfusionMatrix"]][["byClass"]][["Sensitivity"]]),
                      as.vector(.x[["ConfusionMatrix"]][["byClass"]][["Specificity"]]),
                      as.vector(.x[["ConfusionMatrix"]][["byClass"]][["F1"]]))
          ) %>%
  mutate(across(.fns = round, digits = 2))
colnames(metrics_xgb) <- c("AUC", "Sensitivity", "Specificity", "F1")
          

auc <- bind_rows(map_dfr(results_xgb, ~ as.vector(.x[["auc"]])),
                 map_dfr(results_lasso, ~ as.vector(.x[["auc"]])),
                 map_dfr(results_rf, ~ as.vector(.x[["auc"]])),
                 map_dfr(results_nn, ~ as.vector(.x[["auc"]]))) %>%
  round(digits = 2) %>%
  t() %>% 
  as.data.frame()
colnames(auc) <-  c("XGBoost", "Lasso", "RF", "NN")

```

Test difference in AUC

```{r}

# Extract class probabilities
probs_xgb <- results_xgb %>%
  map(~ predict(.x[["model"]], test_prod, type = "prob"))

probs_lasso <- results_lasso %>%
  map(~ predict(.x[["model"]], test_prod, type = "prob"))

probs_rf <- results_rf %>%
  map(~ predict(.x[["model"]], test_prod, type = "prob"))

probs_nn <- results_nn %>%
  map(~ .x[["probs"]][, 2])

# Test auc
test_auc_xgb <- probs_xgb %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, as.numeric(.x[["QAnon"]])))

test_auc_lasso <- probs_lasso %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, as.numeric(.x[["QAnon"]])))

test_auc_rf <- probs_rf %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, as.numeric(.x[["QAnon"]])))

test_auc_nn <- probs_nn %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, .x))

```

# Robustness Checks:
# Feature combinations

```{r}

# Combinations
## 2 sets
names_user_network <- c(names_features_user, names_features_network)
names_user_stylistic <- c(names_features_user, names_features_stylistic)
names_user_text <- c(names_features_user, names_features_text)
names_stylistic_network <- c(names_features_stylistic, names_features_network)
names_stylistic_text <- c(names_features_stylistic, names_features_text)
names_network_text <- c(names_features_network, names_features_text)

## 3 sets
names_user_network_stylistic <- c(names_user_network, names_features_network)
names_user_network_text <- c(names_user_network, names_features_text)
names_user_stylistic_text <- c(names_user_stylistic, names_features_text)
names_stylistic_network_text <- c(names_stylistic_network, names_features_text)


registerDoParallel(cl)

# 2 sets
results_user_network_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_user_network_text)
results_user_stylistic_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_user_stylistic)
results_user_text_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_user_text)
results_stylistic_network_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_stylistic_network)
results_stylistic_text_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_stylistic_text)
results_network_text_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_network_text)

# 3 sets
results_user_network_stylistic_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_user_network_stylistic)
results_user_network_text_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_user_network_text)
results_user_stylistic_text_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_user_stylistic_text)
results_stylistic_network_text_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_stylistic_network_text)

stopCluster(cl)

# List of combinations
results_combinations <- list(results_user_network_xgb, results_user_stylistic_xgb, results_user_text_xgb, results_stylistic_network_xgb, results_stylistic_text_xgb, results_network_text_xgb, results_user_network_stylistic_xgb, results_user_network_text_xgb, results_user_stylistic_text_xgb, results_stylistic_network_text_xgb)

# Test difference in AUC
# Extract class probabilities
probs_combinations <- results_combinations %>%
  map(~ predict(.x[["model"]], test_prod, type = "prob"))

# Test AUC
test_auc_xgb <- probs_xgb %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, as.numeric(.x[["QAnon"]])))

# Test complete model
test_delong <- map(test, ~ roc.test(.x[["roc"]], results_all_xgb[["roc"]]))

```

# Feature selection

```{r}

# Feature selection with lasso (We use the best lasso model trained above on the full feature set)
features_lasso <- coef(results_all_lasso$model$finalModel, results_all_lasso$model$bestTune$lambda)
names_features_selected <- as_vector(data.frame(name = features_lasso@Dimnames[[1]][features_lasso@i + 1], coefficient = features_lasso@x)$name)[-1]

# Train new XGBoost model on features selected by Lasso
registerDoParallel(cl)
results_selection_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_selected)
stopCluster(cl)

# DeLong test
test_delong_selected <- roc.test(results_all_xgb$roc, results_selection_xgb)

```

# Feature importance

```{r}

# Model
mod <- results_all_xgb$model

# Variable importance: Gain
var_imp <- varImp(mod, scale = FALSE)[["importance"]] %>%
  rownames_to_column(var = "feature") %>%
  rename("importance" = "Overall")


# Plot variable importance
# Set theme
theme_set(
  theme_bw() +
    theme(legend.position = c(0.78, 0.9),
          legend.title = element_blank(), legend.direction="vertical",
          legend.text = element_text(colour="black", size=18), 
          legend.background=element_rect(fill="transparent", colour=NA),
          legend.key = element_rect(fill = "transparent", colour = "transparent"),
          legend.key.width = unit(1.25, "cm"), legend.key.height = unit(1.25, "cm")
    ) + 
    theme(axis.text.x=element_text(colour = "black", size=18, vjust=0.5), 
          axis.text.y=element_text(colour = "black", size=18, vjust=0.5),
          axis.title.x=element_text(size=18), 
          axis.title.y=element_text(size=18, vjust=1.5)
    ) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
)

# Top 5

labels <- c("Followers", "Account age", "Following", "Stance", "Hashtags")
levels <- var_imp$feature[1:5]

df_plot <- var_imp %>% 
  slice_max(order_by = importance, n = 5) %>%
  mutate(feature = factor(feature, levels = levels, labels = labels))

plot_imp <- ggplot(df_plot, aes(x = importance, y = reorder(feature, importance))) +
  geom_bar(stat = "identity") +
  scale_x_continuous(
    limits = c(0, 0.35),
    breaks = seq(0, 0.3, 0.1),
    labels = c(0, 0.1, 0.2, 0.3)
  ) +
  xlab("") +
  ylab("")

plot_imp
ggsave(plot_imp, file = str_c("../../Doc/QAnonIdentification/figures/", "var_importance_top5.pdf"), width = 15, height = 10, units = "cm")

# Top 6-10
labels <- c("SBERT 336", "Impressions", "SBERT 311", "SBERT 1", "Military (Empath)")
levels <- var_imp$feature[6:10]

df_plot <- var_imp %>% 
  slice_max(order_by = importance, n = 10) %>%
  slice_min(order_by = importance, n = 5) %>%
  arrange(desc(importance)) %>%
  mutate(feature = factor(feature, levels = levels, labels = labels))

plot_imp <- ggplot(df_plot, aes(x = importance, y = reorder(feature, importance))) +
  geom_bar(stat = "identity") +
  scale_x_continuous(
    limits = c(0, 0.0115),
    breaks = seq(0, 0.012, 0.003),
    labels = c(0, 0.003, 0.006, 0.009, "")
  ) +
  xlab("") +
  ylab("")

plot_imp
ggsave(plot_imp, file = str_c("../../Doc/QAnonIdentification/figures/", "var_importance_top6_10.pdf"), width = 15, height = 10, units = "cm")


```
