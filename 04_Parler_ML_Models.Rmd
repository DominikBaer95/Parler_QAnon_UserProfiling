---
title: "Parler_ML_Models"
author: "Anonymous Author(s)"
date: "25 8 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ##################################################################################################################
#    File analyses parleys (posts/comments)
# ##################################################################################################################

# Environment

```{r library, include=FALSE}

library(tidyverse)
library(caret)
library(doParallel)
library(furrr)
library(xgboost)
library(ranger)
library(glmnet)
library(fastDummies)
library(pROC)
library(verification)

# Python setup
library(reticulate)
library(tensorflow)
library(keras)


# reticulate::py_install('tensorflow', pip = TRUE)
#tf = reticulate::import("tensorflow")
#builtins <- import_builtins() #built in python methods

set.seed(1234)

```

# Directories

```{r paths, include = FALSE}

path_dss <- "" # Project path
# Output data
path_output <- str_c(path_dss, "output/")

```


# Features

```{r}

# Vector with feature names
names_features_user <- c("account_age", "user_followers", "user_following" , "user_posts", "user_comments", "freq_upvotes_posts", "freq_impressions", "freq_upvotes_comments", "freq_downvotes_comments")
names_features_stylistic <- c("freq_handle_user", "freq_hash_user", "freq_pos_user", "freq_long_words_user", "freq_urls", "user_sentiment")
names_features_text <- str_c("text", c(0:383))
names_features_all <- c(names_features_user, names_features_stylistic, names_features_text)
names_features <- c("features_user", "features_stylistic", "features_text", "features_all")

```

# Load data

```{r data, include = FALSE}

# Load training data
load(str_c(path_output, "parler_train.Rdata"))

# Load test data
load(str_c(path_output, "parler_test.Rdata"))

# Load unscaled features
load(str_c(path_output, "features_all_unscaled.Rdata"))

# Load feature names
load(str_c(path_output, "features_names.Rdata"))

features_all_unalterd <- features_all_unalterd %>%
  mutate(across(.cols = c(-creator, -qIndicator, -all_of(names_features_text), -bio, -datatype, -set), ~ if_else(is.na(.x), 0, .x))) %>%
  mutate(qIndicator = factor(qIndicator, labels = c("non.QAnon", "QAnon")))

```

# Train and test split

```{r}

# Proportion of train/test data
p_train <- 0.8

# Create index for train and test split
index_training <- createDataPartition(features_all_unalterd$qIndicator, p = p_train, list = FALSE, times = 1)

# Extract users for testing and training split
users_train <- features_all_unalterd %>%
  dplyr::select(creator) %>%
  dplyr::slice(index_training)

users_test <- features_all_unalterd %>%
  dplyr::select(creator) %>%
  dplyr::slice(-index_training)

# Append features for users in respective split
# Unbalanced: Training
train_ub <- features_all_unalterd %>%
  anti_join(users_test, by = "creator") %>%
  dplyr::select(-creator) %>%
  mutate(qIndicator = factor(qIndicator, labels = c("non.QAnon", "QAnon"))) %>%
  dplyr::select(qIndicator, all_of(names_features_all))

# Testing
test <- features_all_unalterd %>%
  anti_join(users_train, by = "creator") %>%
  dplyr::select(-creator) %>%
  mutate(qIndicator = factor(qIndicator, labels = c("non.QAnon", "QAnon"))) %>%
  dplyr::select(qIndicator, all_of(names_features_all))

# Number of QAnon in samples
# Train
n_qanon_train <- sum(train_ub$qIndicator == "QAnon")
# Test
n_qanon_test <- sum(test$qIndicator == "QAnon")

# Production data
train_prod <- train_ub %>% group_by(qIndicator) %>% slice_sample(n = n_qanon_train) %>% ungroup()
test_prod <- test %>% group_by(qIndicator) %>% slice_sample(n = n_qanon_test) %>% ungroup()

```

Parallel processing

```{r}

cl <- makePSOCKcluster(10)
registerDoParallel(cl)
#plan(multisession, workers = 10)

```

## Train Control
```{r trcntrl, include=FALSE}

trcontrol = trainControl(
    method = "cv",
    number = 10,
    #repeats = 5,
    verboseIter = TRUE,
    returnData = FALSE,
    returnResamp = "none",
    classProbs = TRUE, # set to TRUE for AUC to be computed
    summaryFunction = twoClassSummary,
    allowParallel = TRUE
  )

```

## Gradient Boosting

```{r gradient boosting, include=FALSE}

fit_xgb <- function(data_train, data_test, feature_set){
  
  # data_train: dataset to train the model
  # feature set: character vector of features to use for modeling
  
  formula_features <- formula(str_c("qIndicator ~ ", str_c(feature_set, collapse = "+")))
  
  # Model Setup: XGBoost
  
  model_xgb <- caret::train(formula_features,
                            data = data_train,
                            method = "xgbTree",
                            metric = "ROC",
                            trControl = trcontrol,
                            preProcess=c("center", "scale"),
                            tuneLength = 5
                            )
  
  # Prediction: XGBoost
  pred_xgb <- predict(model_xgb, data_test)

  # ROC: XGBoost
  roc_xgb <- roc(data_test$qIndicator, as.numeric(pred_xgb)) 
  roc_plot_xgb <- ggroc(roc_xgb)

  # AUC: XGBoost
  auc_xgb <- auc(roc_xgb)
  
  # Confusion Matrix: XGBoost
  cm_xgb <- confusionMatrix(pred_xgb, data_test$qIndicator, positive = "QAnon", mode = "everything")
  
  output <- list(model_xgb, pred_xgb, roc_xgb, auc_xgb, cm_xgb)
  names(output) <- c("model", "prediciton", "roc", "auc", "ConfusionMatrix")
  return(output)
}

results_user_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_user)
results_stylistic_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_stylistic)
results_text_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_text)
results_all_xgb <- fit_xgb(data_train = train_prod, data_test = test_prod, feature_set = names_features_all)

results_xgb <- list(results_user_xgb, results_stylistic_xgb, results_text_xgb, results_all_xgb)
names(results_xgb) <- names_features

save(results_xgb, file = str_c(path_dss, "output/", "results_xgb.Rdata"))

```

## Lasso Regression

```{r lasso regression, include=FALSE}

fit_lasso <- function(data_train, data_test, feature_set){
  
  # data_train: dataset to train the model
  # feature set: character vector of features to use for modeling
  
  formula_features <- formula(str_c("qIndicator ~ ", str_c(feature_set, collapse = "+")))
  
  # Set up GridSearch for Lasso:
  lasso_grid <- expand.grid(
    alpha = 1,
    lambda = 10^seq(-3, 3, length = 100)
  )
  
  # Train Lasso model:
  model_lasso <- caret::train(formula_features,
                              data = data_train,
                              method = "glmnet",
                              metric = "ROC",
                              trControl = trcontrol,
                              preProcess=c("center", "scale"),
                              tuneGrid = lasso_grid
                              )

  # Prediction: Lasso
  pred_lasso <- predict(model_lasso, data_test)

  # ROC: Lasso
  roc_lasso <- roc(data_test$qIndicator, as.numeric(pred_lasso)) 
  roc_plot_lasso <- ggroc(roc_lasso)

  # AUC: Lasso
  auc_lasso <- auc(roc_lasso)
  
  # Confusion Matrix: Lasso
  cm_lasso <- confusionMatrix(pred_lasso, data_test$qIndicator, positive = "QAnon", mode = "everything")
  
  output <- list(model_lasso, pred_lasso, roc_lasso, auc_lasso, cm_lasso)
  names(output) <- c("model", "prediciton", "roc", "auc", "ConfusionMatrix")
  return(output)
}

results_user_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_user)
results_stylistic_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_stylistic)
results_text_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_text)
results_all_lasso <- fit_lasso(data_train = train_prod, data_test = test_prod, feature_set = names_features_all)

results_lasso <- list(results_user_lasso, results_stylistic_lasso, results_text_lasso, results_all_lasso)
names(results_lasso) <- names_features

save(results_lasso, file = str_c(path_dss, "output/", "results_lasso.Rdata"))

```

## Random Forest

```{r random forest, include=FALSE}

fit_rf <- function(data_train, data_test, feature_set){
  
  # data_train: dataset to train the model
  # feature set: character vector of features to use for modeling
  
  formula_features <- formula(str_c("qIndicator ~ ", str_c(feature_set, collapse = "+")))
  
  # Model Setup: Random Forest 
  model_rf <- caret::train(formula_features,
                           data = data_train,
                           method = "ranger",
                           metric = "ROC",
                           trControl = trcontrol,
                           preProcess=c("center", "scale"),   
                           tuneLength = 10
                           )
  
  # Prediction: Random Forest
  pred_rf <- predict(model_rf, data_test)

  # ROC: Random Forest
  roc_rf <- roc(data_test$qIndicator, as.numeric(pred_rf)) 
  roc_plot_rf <- ggroc(roc_rf)

  # AUC: Random Forest
  auc_rf <- auc(roc_rf)
  
  # Confusion Matrix: Random Forest
  cm_rf <- confusionMatrix(pred_rf, data_test$qIndicator, positive = "QAnon", mode = "everything")
  
  output <- list(model_rf, pred_rf, roc_rf, auc_rf, cm_rf)
  names(output) <- c("model", "prediciton", "roc", "auc", "ConfusionMatrix")
  return(output)
}

results_user_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_user)
results_stylistic_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_stylistic)
results_text_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_text)
results_all_rf <- fit_rf(data_train = train_prod, data_test = test_prod, feature_set = names_features_all)

results_rf <- list(results_user_rf, results_stylistic_rf, results_text_rf, results_all_rf)
names(results_rf) <- names_features

save(results_rf, file = str_c(path_dss, "output/", "results_rf.Rdata"))

```

## Neural Network

```{r neural network, include=FALSE}

fit_nn <- function(data_train, data_test, feature_set){
  
  # Remove previous keras models
  keras::k_clear_session()
  
  # data_train: dataset to train the model
  # feature set: character vector of features to use for modeling
  
  formula_features <- formula(str_c("qIndicator ~ ", str_c(feature_set, collapse = "+")))
  
  # Preprocess input for keras
  df.training <- data_train %>%
    dummy_cols(remove_first_dummy = TRUE) %>%
    dplyr::select(-qIndicator) %>%
    mutate(qIndicator = as_factor(qIndicator_QAnon)) %>%
    group_by(qIndicator) %>%
    mutate(id = row_number())
  
  df.train <- df.training %>%
    slice_sample(prop = 0.8) %>%
    ungroup()
  
  df.validation <- df.training %>%
    anti_join(df.train, by = "id") %>%
    ungroup() %>%
    dplyr::select(-id)
    
  df.train <- df.train %>% dplyr::select(-id) 
  
  df.test <- data_test %>%
    dummy_cols(remove_first_dummy = TRUE) %>%
    dplyr::select(-qIndicator) %>%
    mutate(qIndicator = as_factor(qIndicator_QAnon))
  
  pp <- preProcess(subset(df.train, select = -qIndicator), method = c("center", "scale"))
  df.train <- predict(pp, df.train)
  df.validation <- predict(pp, df.validation)
  df.test <- predict(pp, df.test)
  
  # Training datasets
  x_train <- df.train %>% 
    dplyr::select(-qIndicator) %>%
    dplyr::select(all_of(feature_set)) %>%
    as.matrix()
  y_train <- to_categorical(df.train$qIndicator)
  
  # Validation datasets
  x_val <- df.validation %>%
    dplyr::select(-qIndicator) %>%
    dplyr::select(all_of(feature_set)) %>%
    as.matrix()
  y_val <- to_categorical(df.validation$qIndicator)
  
  # Test datasets
  x_test <- df.test %>% 
    dplyr::select(-qIndicator) %>%
    dplyr::select(all_of(feature_set)) %>%
    as.matrix()
  y_test <- to_categorical(df.test$qIndicator)
  
  # simple early stopping
  es <- callback_early_stopping(monitor="val_loss", mode="min", verbose=2, patience=50)
  mc <- callback_model_checkpoint("best_model.h5", monitor="val_loss", mode="min", verbose=2, save_best_only=TRUE)
  
  # Network design (NN with 3 hidden layers and ReLu activation function )
  model <- keras_model_sequential()
  model %>%
  # Input layer
    layer_dense(units = 300, activation = "relu", input_shape =  ncol(x_train)) %>%
  # Hidden layer
    layer_dense(units = 100, activation = "relu") %>%
    layer_dense(units = 30, activation = "relu") %>%
    layer_dense(units = 10, activation = "relu") %>%
  # Output layer
    layer_dense(units = 2, activation = "sigmoid")
  
  # Network configuration
  history <- model %>% compile(
   loss = "binary_crossentropy",
   optimizer = "adam",
   metrics = keras$metrics$AUC()
   )
  
  # Fit Neural Network
  model_nn <- model %>% fit(x = x_train, y = y_train, 
                shuffle = T,
                batch_size = 32,
                validation_data = list(x_val, y_val),
                epochs = 1000,
                view_metrics = FALSE,
                verobse = 2,
                callbacks = list(es, mc)
                )
  
  # Prediction: Neural Network
  predictions <- model %>% predict(x_test) %>% `>`(0.5) %>% k_cast("int32")
  pred_nn <- as.data.frame(as.matrix(predictions))$V2
  
  probs_nn <- model %>% predict(x_test)
  
  # ROC: Neural Network
  roc_nn <- roc(df.test$qIndicator, pred_nn)
  roc_plot_nn <- ggroc(roc_nn)
  
  # AUC: Neural Network
  auc_nn <- auc(roc_nn)
  
  # Confusion Matrix: NN
  cm_nn <- confusionMatrix(as.factor(pred_nn), as.factor(df.test$qIndicator), positive = "1", mode = "everything")
  
  output <- list(model_nn, pred_nn, probs_nn, roc_nn, auc_nn, cm_nn)
  names(output) <- c("model", "prediciton", "probs", "roc", "auc", "ConfusionMatrix")
  return(output)
}

results_user_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_user)
results_stylistic_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_stylistic)
results_text_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_text)
results_all_nn <- fit_nn(data_train = train_prod, data_test = test_prod, feature_set = names_features_all)

results_nn <- list(results_user_nn, results_stylistic_nn, results_text_nn, results_all_nn)
names(results_nn) <- names_features

save(results_nn, file = str_c(path_dss, "output/", "results_nn.Rdata"))

```

# Collect table of AUCs

```{r table AUCs}

metrics_xgb <- results_xgb %>%
  map_dfr(~ bind_cols(as.vector(.x[["auc"]]),
                      as.vector(.x[["ConfusionMatrix"]][["byClass"]][["Sensitivity"]]),
                      as.vector(.x[["ConfusionMatrix"]][["byClass"]][["Specificity"]]),
                      as.vector(.x[["ConfusionMatrix"]][["byClass"]][["F1"]]))
          ) %>%
  mutate(across(.fns = round, digits = 2))
colnames(metrics_xgb) <- c("AUC", "Sensitivity", "Specificity", "F1")
          

auc <- bind_rows(map_dfr(results_xgb, ~ as.vector(.x[["auc"]])),
                 map_dfr(results_lasso, ~ as.vector(.x[["auc"]])),
                 map_dfr(results_rf, ~ as.vector(.x[["auc"]])),
                 map_dfr(results_nn, ~ as.vector(.x[["auc"]]))) %>%
  round(digits = 2) %>%
  t() %>% 
  as.data.frame()
colnames(auc) <-  c("XGBoost", "Lasso", "RF", "NN")

```

Test difference in AUC

```{r}

# Extract class probabilities
probs_xgb <- results_xgb %>%
  map(~ predict(.x[["model"]], test_prod, type = "prob"))

probs_lasso <- results_lasso %>%
  map(~ predict(.x[["model"]], test_prod, type = "prob"))

probs_rf <- results_rf %>%
  map(~ predict(.x[["model"]], test_prod, type = "prob"))

probs_nn <- results_nn %>%
  map(~ .x[["probs"]][, 2])

# Test auc
test_auc_xgb <- probs_xgb %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, as.numeric(.x[["QAnon"]])))

test_auc_lasso <- probs_lasso %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, as.numeric(.x[["QAnon"]])))

test_auc_rf <- probs_rf %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, as.numeric(.x[["QAnon"]])))

test_auc_nn <- probs_nn %>%
  map(~ roc.area(as.numeric(test_prod$qIndicator)-1, .x))

```

